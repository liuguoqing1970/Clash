{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef33deb-b188-4429-b43e-86bdd8e60f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "start ='2020-01-02'\n",
    "now = dt.datetime.now().date()\n",
    "\n",
    "allstocks = 'RichardStocks.xlsx'\n",
    "output = 'VCPlog.xlsx'\n",
    "\n",
    "stocklist = pd.read_excel(f\"/Users/benjaminluk/PycharmProjects/VCPscreener/{allstocks}\")  #change this\n",
    "\n",
    "# Intermediate files\n",
    "Template_Screen_file = 'VCP_template_screen.xlsx'\n",
    "RS_Ranked_File = 'RS_Ranked.xlsx'\n",
    "Output_file = f'/Users/benjaminluk/PycharmProjects/VCPscreener/{output}' #change this\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "RS_percentile = 0.3 #top 30% of RS Rating wanted\n",
    "delta = 3 # +-3 days from minimum or maximum point to find lowest/highest close\n",
    "peakupperbound = 1.02 #upper bound of all other peaks relative to first peak\n",
    "peaklowerbound = 0.95 #lower bound of all other peaks relative to first peak\n",
    "ddleniency = 0.30 #each max to min length is at least 0.3 of previous\n",
    "\n",
    "\n",
    "\n",
    "exportList = []\n",
    "exportList.append(['Stock', \"RS_Rating\", \"50 Day MA\", \"150 Day MA\", \"200 Day MA\", \"52 Week Low\", \"52 week High\"])\n",
    "\n",
    "for i in stocklist.index:\n",
    "    stock = str(stocklist[\"Symbol\"][i])\n",
    "    try:\n",
    "        df = pdr.get_data_yahoo(stock, start, now)\n",
    "\n",
    "        smaUsed = [50, 150, 200]\n",
    "        for x in smaUsed:\n",
    "            sma = x\n",
    "            df[\"SMA_\" + str(sma)] = round(df.iloc[:, 4].rolling(window=sma).mean(), 2)\n",
    "\n",
    "        currentClose = df[\"Adj Close\"][-1]\n",
    "        moving_average_50 = df[\"SMA_50\"][-1]\n",
    "        moving_average_150 = df[\"SMA_150\"][-1]\n",
    "        moving_average_200 = df[\"SMA_200\"][-1]\n",
    "        low_of_52week = min(df[\"Adj Close\"][-260:])\n",
    "        high_of_52week = max(df[\"Adj Close\"][-260:])\n",
    "\n",
    "\n",
    "        threemonthclose = df['Adj Close'][-63]\n",
    "        sixmonthclose = df['Adj Close'][-126]\n",
    "        ninemonthclose = df['Adj Close'][-189]\n",
    "        twelvemonthclose = df['Adj Close'][-252]\n",
    "\n",
    "\n",
    "        RS_Rating = (threemonthclose / currentClose) * 2 + (sixmonthclose / currentClose) + (ninemonthclose / currentClose) + (twelvemonthclose / currentClose)\n",
    "\n",
    "\n",
    "        try:\n",
    "            moving_average_200_20past = df[\"SMA_200\"][-20]\n",
    "        except Exception:\n",
    "            moving_average_200_20past = 0\n",
    "\n",
    "        print(\"Checking \" + stock + \".....\")\n",
    "\n",
    "        # Condition 1: Current Price > 150 SMA and > 200 SMA\n",
    "        if (currentClose > moving_average_150 and currentClose > moving_average_200):\n",
    "            cond1 = True\n",
    "        else:\n",
    "            cond1 = False\n",
    "        # Condition 2: 150 SMA and > 200 SMA\n",
    "        if (moving_average_150 > moving_average_200):\n",
    "            cond2 = True\n",
    "        else:\n",
    "            cond2 = False\n",
    "        # Condition 3: 200 SMA trending up for at least 1 month (ideally 4-5 months)\n",
    "        if (moving_average_200 > moving_average_200_20past):\n",
    "            cond3 = True\n",
    "        else:\n",
    "            cond3 = False\n",
    "        # Condition 4: 50 SMA> 150 SMA and 50 SMA> 200 SMA\n",
    "        if (moving_average_50 > moving_average_150 and moving_average_50 > moving_average_200):\n",
    "            cond4 = True\n",
    "        else:\n",
    "            cond4 = False\n",
    "        # Condition 5: Current Price > 50 SMA\n",
    "        if (currentClose > moving_average_50):\n",
    "            cond5 = True\n",
    "        else:\n",
    "            cond5 = False\n",
    "        # Condition 6: Current Price is at least 30% above 52 week low (Many of the best are up 100-300% before coming out of consolidation)\n",
    "        if (currentClose >= 1.30 * low_of_52week):\n",
    "            cond6 = True\n",
    "        else:\n",
    "            cond6 = False\n",
    "        # Condition 7: Current Price is within 25% of 52 week high\n",
    "        if (currentClose >= 0.75 * high_of_52week):\n",
    "            cond7 = True\n",
    "        else:\n",
    "            cond7 = False\n",
    "\n",
    "\n",
    "        if (cond1 and cond2 and cond3 and cond4 and cond5 and cond6 and cond7):\n",
    "            exportList.append([stock, RS_Rating, moving_average_50,\n",
    "                                            moving_average_150, moving_average_200,\n",
    "                                            low_of_52week, high_of_52week])\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        print(\"No data on \" + stock)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with xlsxwriter.Workbook(Template_Screen_file) as workbook:\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    for row_num, data in enumerate(exportList):\n",
    "        worksheet.write_row(row_num, 0, data)\n",
    "\n",
    "\n",
    "#=================================================#\n",
    "\n",
    "#Sort by RS_Rating, want top 30%\n",
    "xl = pd.ExcelFile(Template_Screen_file)\n",
    "df = xl.parse(\"Sheet1\")\n",
    "df = df.sort_values(by=[\"RS_Rating\"], ascending = False)\n",
    "lengthneeded = int(len(df) * RS_percentile)\n",
    "df = df[: lengthneeded]\n",
    "\n",
    "writer = pd.ExcelWriter(RS_Ranked_File)\n",
    "df.to_excel(writer,sheet_name='Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "#================================================#\n",
    "\n",
    "##VCP Detection Main Code\n",
    "\n",
    "def localmaxmin(datamaxmin):\n",
    "    min_max = np.diff(np.sign(np.diff(datamaxmin))).nonzero()[0] + 1  # local min & max\n",
    "    l_min = (np.diff(np.sign(np.diff(datamaxmin))) > 0).nonzero()[0] + 1  # local min\n",
    "    l_max = (np.diff(np.sign(np.diff(datamaxmin))) < 0).nonzero()[0] + 1  # local max\n",
    "    # +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "    return l_min, l_max\n",
    "\n",
    "\n",
    "def maxminrange(datarange, y_pol, delta):\n",
    "    # extend the suspected x range:\n",
    "    # how many ticks to the left and to the right from local minimum on x axis\n",
    "\n",
    "    dict_min = dict()\n",
    "    dict_max = dict()\n",
    "    dict_x = dict()\n",
    "\n",
    "    df_len = len(datarange)  # number of rows in dataset\n",
    "\n",
    "    l_min = localmaxmin(y_pol)[0]\n",
    "    l_max = localmaxmin(y_pol)[1]\n",
    "\n",
    "    # l_min value ranges\n",
    "    for element in l_min:  # x coordinates of suspected minimums\n",
    "        l_bound = element - delta  # lower bound (left)\n",
    "        u_bound = element + delta  # upper bound (right)\n",
    "        x_range = range(l_bound, u_bound + 1)  # range of x positions where we SUSPECT to find a low\n",
    "        dict_min[\n",
    "            element] = x_range  # just helpful dictionary that holds suspected x ranges for further visualization strips\n",
    "\n",
    "        min_loc_list = list()\n",
    "        for x_element in x_range:\n",
    "            if x_element > 0 and x_element < df_len:  # need to stay within the dataframe\n",
    "                # y_loc_list.append(ticker_df.Low.iloc[x_element])   # list of suspected y values that can be a minimum\n",
    "                min_loc_list.append(datarange['Low'].iloc[x_element])\n",
    "                # print(y_loc_list)\n",
    "                # print('ticker_df.Low.iloc[x_element]', ticker_df.Low.iloc[x_element])\n",
    "        dict_min[element] = min_loc_list  # key in element is suspected x position of minimum\n",
    "        # to each suspected minimums we append the price values around that x position\n",
    "        # so 40: [53.70000076293945, 53.93000030517578, 52.84000015258789, 53.290000915527344]\n",
    "        # x position: [ 40$, 39$, 41$, 45$]\n",
    "\n",
    "    for element in l_max:  # x coordinates of suspected minimums\n",
    "        l_bound = element - delta  # lower bound (left)\n",
    "        u_bound = element + delta  # upper bound (right)\n",
    "        x_range = range(l_bound, u_bound + 1)  # range of x positions where we SUSPECT to find a low\n",
    "        dict_max[\n",
    "            element] = x_range  # just helpful dictionary that holds suspected x ranges for further visualization strips\n",
    "\n",
    "        max_loc_list = list()\n",
    "        for y_element in x_range:\n",
    "            if y_element > 0 and y_element < df_len:  # need to stay within the dataframe\n",
    "\n",
    "                max_loc_list.append(datarange['High'].iloc[y_element])\n",
    "                # print(y_loc_list)\n",
    "                # print('ticker_df.Low.iloc[x_element]', ticker_df.Low.iloc[x_element])\n",
    "        dict_max[element] = max_loc_list\n",
    "\n",
    "    return dict_min, dict_max\n",
    "\n",
    "\n",
    "def VCP_finder(datafind, delta, peakupperbound, peaklowerbound, ddleniency):\n",
    "\n",
    "    ok = []\n",
    "    windowdeg = [[40, 11], [60, 11], [80, 11], [100, 9], [120, 9]]\n",
    "    currentWindow = [0, 0, 0, 0, 0]\n",
    "\n",
    "    # data splicing for rolling windows\n",
    "    buysignal = False\n",
    "\n",
    "    for i in np.arange(0, len(windowdeg) - 1, 1):\n",
    "        window = windowdeg[i][0]\n",
    "        polydeg = windowdeg[i][1]\n",
    "\n",
    "        datanow = datafind[-window + 1:]\n",
    "        predata = datafind[-2 * window + 1: -window]\n",
    "\n",
    "        # fit polynomial curve through data\n",
    "        # choose the input and output variables\n",
    "        x, y = np.arange(0, window - 1, 1), datanow['Adj Close']\n",
    "        # curve fit\n",
    "        popt = np.polyfit(x, y, polydeg)\n",
    "        y_pol = np.polyval(popt, x)\n",
    "\n",
    "        # minimum and maximum ranges\n",
    "        dict_min = maxminrange(datanow, y_pol, delta)[0]\n",
    "        dict_max = maxminrange(datanow, y_pol, delta)[1]\n",
    "\n",
    "        min_loclist = localmaxmin(y_pol)[0]\n",
    "        max_loclist = localmaxmin(y_pol)[1]\n",
    "\n",
    "        for k in min_loclist:\n",
    "            dict_min[k] = np.min(dict_min[k])\n",
    "\n",
    "        min_list = list(dict_min.values())\n",
    "        min_values = np.array(min_list)\n",
    "\n",
    "        for j in max_loclist:\n",
    "            dict_max[j] = np.max(dict_max[j])\n",
    "\n",
    "        max_list = list(dict_max.values())\n",
    "        max_values = np.array(max_list)\n",
    "\n",
    "        ###VCP conditions\n",
    "        conditions = np.zeros(5)\n",
    "\n",
    "        ##1. Stage 2 growth present/ Past uptrend\n",
    "        xs, ys = np.arange(0, window - 1, 1), predata['Adj Close']\n",
    "        prepopt = np.polyfit(xs, ys, 1)\n",
    "        if prepopt[0] > 0:\n",
    "            conditions[0] = True\n",
    "\n",
    "        ##2. wedgeup/ triangle ascending\n",
    "        if (len(min_values) > len(max_values)):  # make sure graph starts with a peak\n",
    "            min_values = min_values[1:]\n",
    "        elif (len(min_values) < len(max_values)):\n",
    "            max_values = max_values[:-1]\n",
    "\n",
    "        if ((min_values + max_values).size != 0):\n",
    "            if (len(min_list) == len(max_list)) and ((min_loclist[0] < max_loclist[0])):\n",
    "                max_values = max_values[:-1]                # making sure the window has pattern as follows:\n",
    "                min_values = min_values[1:]                 #          . . .\n",
    "                                                            #           . . .          (max first followed by min, and end with min)\n",
    "\n",
    "\n",
    "        if len(min_values) > 1:\n",
    "            troughline = np.polyfit(np.arange(0, len(min_values), 1), min_values, 1)[0]    #fit a linear line through minimums\n",
    "        else:\n",
    "            troughline = 0\n",
    "\n",
    "\n",
    "        if troughline > 0:  # ascending troughs, check gradient > 0\n",
    "            conditions[1] = True\n",
    "        else:\n",
    "            conditions[1] = False\n",
    "\n",
    "        ##3. first peak greater than all other peaks (with leniency parameter)\n",
    "        for p in max_values:\n",
    "            if p < (max_values[0] * peakupperbound) and p > (max_values[0] * peaklowerbound):\n",
    "                conditions[2] = True\n",
    "            else:\n",
    "                conditions[2] = False\n",
    "\n",
    "        if len(max_values) <= 1:  # make sure at least two peaks\n",
    "            conditions[2] = False\n",
    "\n",
    "        ##4. drawdown contracting\n",
    "        drawdowns = np.abs(max_values - min_values)\n",
    "        conditions[3] = all((ddleniency) * earlier <= later for earlier, later in zip(drawdowns, drawdowns[1:])) #check each max min length is shortening\n",
    "\n",
    "\n",
    "        ##5. Decreasing Volume in last peak\n",
    "        if min_loclist.size == 0 and max_loclist.size == 0:  # ignore empty minimum and maximum lists\n",
    "            min_loclist = np.array([0])\n",
    "            max_loclist = np.array([0])\n",
    "        if max_loclist.size == 0:\n",
    "            max_loclist = min_loclist\n",
    "        if min_loclist.size == 0:\n",
    "            min_loclist = max_loclist\n",
    "\n",
    "        lastpeak = max_loclist[-1]\n",
    "        lasttrough = min_loclist[-1]\n",
    "\n",
    "        volumes = datanow['Volume'][lastpeak:lasttrough]\n",
    "\n",
    "        volx = np.arange(0, len(volumes), 1)\n",
    "\n",
    "        if len(volumes) > 1:\n",
    "            volpopt = np.polyfit(volx, volumes, 1)[0]\n",
    "        else:\n",
    "            volpopt = 0\n",
    "\n",
    "        if volpopt < 0:\n",
    "            conditions[4] = True\n",
    "\n",
    "        ## Optional Condition: first wave has > 8% dd\n",
    "        # if drawdowns.size != 0:\n",
    "        #    if (drawdowns[0]/max_values[0]) > 0.10:\n",
    "        #        conditions[5] = True\n",
    "\n",
    "        # print ones where all conditions are True\n",
    "        if all(conditions) == True:\n",
    "            currentWindow[i] = True\n",
    "            buysignal = True\n",
    "\n",
    "\n",
    "    return buysignal, currentWindow\n",
    "\n",
    "####################################################\n",
    "\n",
    "stocklist = df\n",
    "symbols = stocklist['Stock'].tolist()\n",
    "symbols = [e[0:] for e in symbols]\n",
    "signaltickerlist = []\n",
    "\n",
    "\n",
    "#Check all for all tickers if VCP pattern exists\n",
    "for ticker in symbols:\n",
    "    dataall = pdr.get_data_yahoo(ticker, start= start, end= now)\n",
    "    dataall['Date'] = dataall.index\n",
    "    dataall.fillna(0)  # dropping the NaN values\n",
    "\n",
    "    volume = dataall['Volume'][-1]\n",
    "    currentPrice = dataall['Adj Close'][-1]\n",
    "    try:\n",
    "        mktcap = int(pdr.get_quote_yahoo(ticker)['marketCap'])\n",
    "    except IndexError:\n",
    "        mktcap = 0\n",
    "    except KeyError:\n",
    "        mktcap = 0\n",
    "\n",
    "    cry = VCP_finder(dataall, delta=delta, peakupperbound=peakupperbound, peaklowerbound=peaklowerbound, ddleniency=ddleniency)\n",
    "\n",
    "    if cry[0] == True:\n",
    "        signaltickerlist.append([ticker, volume, mktcap, currentPrice])\n",
    "        print(ticker)\n",
    "        print(cry[1])\n",
    "\n",
    "signaltickerlist = (sorted(signaltickerlist))\n",
    "print(signaltickerlist)\n",
    "\n",
    "#=============================================\n",
    "\n",
    "wb = load_workbook(filename=Output_file)\n",
    "ws = wb['Sheet1']\n",
    "\n",
    "for i in signaltickerlist:\n",
    "    ws.append([now, i[0], i[1], i[2], i[3]])\n",
    "\n",
    "wb.save(filename=Output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
